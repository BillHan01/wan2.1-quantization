model:
    model_id: "opensora"
    model_type: 'opensora'  
# remain_fp_regex: embedder|adaLN_modulation|t_block|final_layer|kv_linear|\b(?!cross_)attn\b
# wanx:
# text_embedding.* | time_embedding.* | time_projection.* | head.head
# blocks.*.self_attn.* | blocks.*.cross_attn.* | blocks.*.ffn.*	
remain_fp_regex: text_embedding|time_embedding|time_projection|head\.head|blocks\.\d+\.self_attn\.(?!q$)(?!k$)(?!v$)[^.]+|blocks\.\d+\.o|blocks\.\d+\.ffn.*|cross_attn #|blocks\.\d+\.self_attn\.(?!q$)(?!k$)(?!v$)[^.]+ #blocks\.\d+\.norm(?!1).* # |blocks\.\d+\.ffn.* |blocks\.\d+\.self_attn\.(?!q$)(?!k$)(?!v$)[^.]+
# remain_fp_regex: text_embedding|time_embedding|time_projection|head.head|blocks\.\d+\.cross_attn|blocks\.\d+\.ffn|.o.|norm2|norm3 # \.(?!27|28)\.self_attn|blocks\.\d+\.cross_attn|blocks\.\d+\.ffn
# remain_fp_regex: text_embedding|time_embedding|time_projection|head.head|blocks.1|blocks.2|blocks.3|blocks.4|blocks.5|blocks.6|blocks.7|blocks.8|blocks.9|blocks.10|blocks.11|blocks.12|blocks.13|blocks.14|blocks.15|blocks.16|blocks.17|blocks.18|blocks.19|blocks.20 # 
calib_data:
  save_path: ./quant_data/calib_data_wanx1.pth
weight:
    n_bits: 8
    sym: False
act:
    n_bits: 8
    sym: True
viditq:
  alpha: 0.5665
  layer_name_regex: "" # 27|28

